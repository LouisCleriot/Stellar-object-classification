{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook will try to choose the Best model from a category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the necessary library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.models.RandomForestClassifier import RFClassifier\n",
    "from src.models.SVMClassifier import SVMClassifier\n",
    "from src.models.NaiveBayesClassifier import NaiveBayesClassifier\n",
    "from src.models.KNNClassifier import KNNClassifier\n",
    "from src.models.LogisticRegClassifier import LogisticRegClassifier\n",
    "from src.models.NNClassifier import NNClassifier\n",
    "\n",
    "import os\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model Training Notebook\n",
    "\n",
    "This Jupyter Notebook serves as a documentation and workflow for training the Logistic Regression model. \n",
    "\n",
    "## Data Processing\n",
    "\n",
    "In the following cells, we import the necessary libraries and load the training and testing datasets as well as the trained models. There are 1 variable that can be changed depending on the model we want to compare:\n",
    "* `model_choice` : RF | SVM | KNN | LR | NB | NN |\n",
    "\n",
    "\n",
    "NOTE : Make sure you already made the datasets with the commands:\n",
    "- `make data`\n",
    "- `make features`\n",
    "\n",
    "NOTE : Make sure you already trained the models or downloads them with the commands:\n",
    "- `make download_models`\n",
    "\n",
    "We also perform data preprocessing steps such as encoding labels. Other preprocessing steps such as removing correlations with pca, and scaling the data are done within the pipeline of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load testing data for outlier presence\n",
    "test_with = pd.read_csv('../../data/processed/with_outliers/test.csv')\n",
    "y_test_with = test_with[\"class\"]\n",
    "X_test_with = test_with.drop(\"class\", axis=1)\n",
    "\n",
    "#load the testing data without outlier\n",
    "test_without = pd.read_csv('../../data/processed/without_outliers/test.csv')\n",
    "y_test_without = test_without[\"class\"]\n",
    "X_test_without = test_without.drop(\"class\", axis=1)\n",
    "\n",
    "#load the training class to encode labels\n",
    "y_train_with = pd.read_csv('../../data/processed/with_outliers/train.csv')[\"class\"]\n",
    "y_train_without = pd.read_csv('../../data/processed/without_outliers/train.csv')[\"class\"]\n",
    "\n",
    "#encode labels of testing class once fit on training class\n",
    "label_encoder_with = LabelEncoder().fit(y_train_with)\n",
    "y_test_with = label_encoder_with.transform(y_test_with)\n",
    "label_encoder_without = LabelEncoder().fit(y_train_without)\n",
    "y_test_without = label_encoder_without.transform(y_test_without)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the type of model to use from this list: ['RF', 'SVM', 'KNN', 'LR', 'NB', 'NN']\n",
    "model_choice = 'NB'\n",
    "\n",
    "models_dir = '../../models/'+model_choice+'/'\n",
    "\n",
    "choice_clf = {'RF': RFClassifier(),\n",
    "            'SVM': SVMClassifier(),\n",
    "            'KNN': KNNClassifier(),\n",
    "            'LR': LogisticRegClassifier(),\n",
    "            'NB': NaiveBayesClassifier(),\n",
    "            'NN': NNClassifier()}\n",
    "models = {}\n",
    "for filename in os.listdir(models_dir):\n",
    "    clf = choice_clf[model_choice]\n",
    "    clf.load(new_name=filename[:-7], path=models_dir)\n",
    "    models[filename] = clf.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaiveBayes_with_outliers_oversampled.joblib\n",
      "Inference time:  1.393890380859375e-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      GALAXY       0.97      0.93      0.95     11889\n",
      "         QSO       0.82      0.91      0.86      3792\n",
      "        STAR       0.98      0.99      0.98      4319\n",
      "\n",
      "    accuracy                           0.94     20000\n",
      "   macro avg       0.92      0.94      0.93     20000\n",
      "weighted avg       0.94      0.94      0.94     20000\n",
      "\n",
      "NaiveBayes_without_outliers.joblib\n",
      "Inference time:  2.9258430004119875e-07\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      GALAXY       0.95      0.96      0.95     11605\n",
      "         QSO       0.89      0.84      0.86      3719\n",
      "        STAR       0.98      0.99      0.99      3876\n",
      "\n",
      "    accuracy                           0.94     19200\n",
      "   macro avg       0.94      0.93      0.93     19200\n",
      "weighted avg       0.94      0.94      0.94     19200\n",
      "\n",
      "NaiveBayes_without_outliers_oversampled.joblib\n",
      "Inference time:  2.9426068067550657e-07\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      GALAXY       0.97      0.93      0.95     11605\n",
      "         QSO       0.82      0.91      0.86      3719\n",
      "        STAR       0.98      0.99      0.98      3876\n",
      "\n",
      "    accuracy                           0.94     19200\n",
      "   macro avg       0.92      0.94      0.93     19200\n",
      "weighted avg       0.94      0.94      0.94     19200\n",
      "\n",
      "NaiveBayes_without_outliers_undersampled.joblib\n",
      "Inference time:  2.7858962615331013e-07\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      GALAXY       0.97      0.93      0.95     11605\n",
      "         QSO       0.82      0.91      0.86      3719\n",
      "        STAR       0.98      0.99      0.99      3876\n",
      "\n",
      "    accuracy                           0.94     19200\n",
      "   macro avg       0.92      0.94      0.93     19200\n",
      "weighted avg       0.94      0.94      0.94     19200\n",
      "\n",
      "NaiveBayes_with_outliers_undersampled.joblib\n",
      "Inference time:  2.8493404388427736e-07\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      GALAXY       0.97      0.93      0.95     11889\n",
      "         QSO       0.82      0.91      0.86      3792\n",
      "        STAR       0.98      0.99      0.98      4319\n",
      "\n",
      "    accuracy                           0.94     20000\n",
      "   macro avg       0.92      0.94      0.93     20000\n",
      "weighted avg       0.94      0.94      0.94     20000\n",
      "\n",
      "NaiveBayes_with_outliers.joblib\n",
      "Inference time:  4.2144060134887694e-07\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      GALAXY       0.95      0.96      0.95     11889\n",
      "         QSO       0.89      0.84      0.87      3792\n",
      "        STAR       0.98      0.99      0.98      4319\n",
      "\n",
      "    accuracy                           0.94     20000\n",
      "   macro avg       0.94      0.93      0.93     20000\n",
      "weighted avg       0.94      0.94      0.94     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    print(name)\n",
    "    #check if name has a certain string\n",
    "    if \"_without_\" in name :\n",
    "        start_time = time.time()\n",
    "        y_pred = model.predict(X_test_without)\n",
    "        end_time = time.time()\n",
    "        inference_time = (end_time - start_time)/len(y_pred)\n",
    "        print(\"Inference time: \", inference_time)\n",
    "        print(classification_report(label_encoder_without.inverse_transform(y_test_without), label_encoder_without.inverse_transform(y_pred)))\n",
    "    else:\n",
    "        start_time = time.time()\n",
    "        y_pred = model.predict(X_test_with)\n",
    "        end_time = time.time()\n",
    "        inference_time = (end_time - start_time)/len(y_pred)\n",
    "        print(\"Inference time: \", inference_time)\n",
    "        print(classification_report(label_encoder_with.inverse_transform(y_test_with),label_encoder_with.inverse_transform(y_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
